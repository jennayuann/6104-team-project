# Design Summary

## Summary of Changes Made from Original Design

| Feature | Original Design | Final Implementation | How It Changed |
|---------|----------------|---------------------|----------------|
| **LinkedIn Import** | OAuth/API integration or scraping | File upload (CSV/JSON) | Switched from API/scraping to user-uploaded export files for ethical compliance and LinkedIn restrictions |
| **User Flow** | Separate steps for account creation, profile setup, network creation | Unified flow with guided onboarding | Streamlined into a single guided process that creates account, profile, and network automatically |
| **Export** | Not specified | CSV export functionality | Added new feature to allow users to download their network data for backup/portability |
| **Tutorials** | Not specified | Dedicated tutorials page with step-by-step guides | Added educational content to help users understand platform features and workflows |
| **Network Management** | Manual node/edge addition | Automated additions via "Add Connection" button | Single-button flow that creates node, adds to network, and creates edge automatically |
| **Search** | Semantic search only | Semantic + standard text/filter search | Added traditional search alongside AI-powered semantic search for flexibility especially in the case of technical issues with semantic search |

### Disambiguation of Mutliple Users

This is one concept that we discussed (more a feature) we determined through meetings with our TA and amoung ourselves that it may not have been critical to the functionality and purpose of our project. Therefore it was deprioritized. Additionally the user flow was the main reason we changed the design of this function. In the case you add 600 people the balance between allowing the user to understand the matching that is going on and inttervene in the case of a problem while not bothering them too much is difficult. With intelligent matching the question is a complex one. "Are these 2 bits of data representative of the same people?" It is complex and messing it up can greatly hurt one user's experience and also the privacy of another user. Since this would allow a user to connect to and view data of a person someone else added.

In researching similar solutions we saw 2 options: Complex algorithms that are trained for the purpose of disambiguation specifically, and a simple rule based system that is accountable and easy to understand. The best mix for us is a simple rule based system which lets us be confident in the disambiguation and no have to require user input to make it happen. Therefore we implemented this system for LinkedIn imports only and match based on the unique profile url. This simple rule enables the connection we discussed without complicating profiles or user flows. However this rule is not implemented between different accounts due to the privacy considerations. Though possible we think that the privacy considerations would be outside of the scope of the ethical analysis we did for the project.

### Ethics of importing
Our original plan was to use a system similar to those commercially available online, which scrape profile information on a per-profile basis (e.g., profile_id → information). However, despite these sources existing, many are vague about how they accomplish this. Upon reviewing the LinkedIn API, we discovered that a change was made around six years ago to limit the amount of information accessible through standard means. This is because LinkedIn decided to monetize access to this data, making it available only to their corporate partners—requiring negotiation of a hefty payment package. Despite these factors, it is clearly still possible to get information from LinkedIn, and since LinkedIn still permits it (for a price), the use of that data is not inherently unethical. However, after this research, it became clear that knowingly subverting the explicit changes LinkedIn has made would be unethical.

The second option I considered was using a method similar to "Sign in with LinkedIn." If you have ever signed in with Google, you may have been prompted with a question asking to share your email or contacts with the app. My hope was that, since this is a common paradigm centered around the user's own information, this would be possible with LinkedIn. However, from developer testimonials, it appears that the sign in with LinkedIn feature is primarily designed for authentication, not for streamlined integration or data import. Therefore, the information we could access would be limited.

This put me in a difficult position to design an importing system that would both meet our ethical standards and comply with the restrictions set by LinkedIn. While continuing to scrape could be possible (and many others do, even scraping and selling the data of accounts they do not own), that approach seemed inappropriate.

In searching for apps that provide value while allowing import of data they are not directly connected to, I found an example: https://www.swipestats.io. This service allows users of dating apps like Tinder to visualize their swiping and interaction history. Dating app companies do not like this use case, because it is often used by people to comment on the futility of dating apps—creating visualizations about the ratio of time spent using the app to actual dates or relationships. As a result, the app cannot integrate directly with Tinder through an API or similar mechanism. The solution they developed is to allow users to import their own data via a file upload. The app provides instructions on how to request your data from Tinder and which file to upload to quickly import everything. In fact, it does not offer any other way to add data.

Despite these limitations, the app is undoubtedly popular. You can see hundreds of people posting its visualizations in forums like https://www.reddit.com/r/Tinder/. This inspired the implementation of our import concept: we allow users to request their LinkedIn data (with instructions on how to do so), then import that data into our system—along with supporting other manual additions and data from different sources (since an LLM will review any file passed in and attempt to match it dynamically to our internal concept).

### Frontend Design

A critical aspect of frontend design that I think is really important and that we learned throughout this process is the question of separating what we have in the background from what the user actually needs to do. Throughout the process, it seems like in design we didn’t think through that as much as we should have, but it immediately became apparent that that’s the first thing users cared about. They really cared about the journey to get to an end. For example, part of what they were thinking about when they looked at the frontend was not “can I sign in,” which is something they were able to do successfully, but the process of signing in. So how can we break this up so that while it all may be using the same sign-in concept, it makes it clear to the user what they’re doing at each step? Ask me for my name first, then my picture, then the key pieces of information, then give me the optional pieces of information or some clues on the best way to start, and then finally create my account—rather than having all of that available at the same time.

The second thing that’s really important, I think, is that naming and decisions about what elements and buttons are included should not be related to the backend design at all. The names for what things technically are—like nodes and edges—are not relevant to users. While that makes it easy for us to discuss design decisions, it makes it very difficult for a user to come in and use the app if they haven’t thought about it the way we have.

Finally, I think the idea of simplifying what the user is doing is important. A discussion that we had during user testing was that apps like Instagram and other modern software are designed to seamlessly put you on little paths. Even if they have a lot of extra settings and things you can interact with, the real goal is that they confidently place you on a small sequence of actions to do what you want to do. If you want to post, it puts you in a little carousel that takes you through the steps of posting. If you want to comment, it puts you in a set of actions where you click on the thing you want to comment on, write what you want, add tags or emojis, then click send. If you want to share something, you click the share button and then there are maybe three or four things you have to do, but it’s done in a tiny, guided sequence.

This was very similar to how they were discussing the processes we were asking them to do as tasks. They were wondering: if we knew these were important tasks, why couldn’t we design the UI to match that? I thought this was a really good callout, and it really shaped our choices when designing the second version after we got our feedback.

### Semantic-Search
For semantic search, our original proposal was basically just “we want smart semantic search,” and we didn’t know the exact tool at the time. Pretty early on, we found txtai and decided to use it. But once we actually tried to deploy it, we realized pretty fast that txtai was way harder to run than we thought. It needs its own separate server, and hosting that on Render ended up being a huge hassle. It kept randomly shutting down for no reason with zero logs explaining why and still being displayed as "deployed" on Render, which made the whole thing super unreliable and honestly pretty stressful.

Because of that, we tried pivoting to a Google Gemini fallback. But the problem there was that every query needed us to send Gemini the user’s entire set of connections, and that hit token limits almost immediately, especially for users with a lot of connections. So that wasn’t really realistic either.

So we went back to txtai and just kept a simple keyword-style search as the fallback. This time, we just paid for Render's subscription that keeps the service alive with no downtime for inactivity, and that finally fixed the issues (at least we think so after many hours of monitoring).

We also changed how we displayed the semantic results. At first, we were showing the raw semantic score txtai returns, but testers didn’t know what that number meant or why something was ranked higher or lower. So we switched it to a percentage score, which felt way more intuitive with higher percentage = more similar to your query. We also realized txtai returns basically everything that’s even slightly relevant, so we had to play around with a minimum semantic score so that every search didn’t return every single connection.

### Network Visualization and Model
For the network model and visualization, our original plan was to let users manually add nodes and edges to build their network graph, thinking this would give them the most flexibility. But as soon as we started testing, it became obvious that this was way too tedious and confusing, especially for users importing a lot of connections. We quickly pivoted to a more automated approach: now, whenever a user imports LinkedIn data or adds a connection manually, the system automatically creates the corresponding node, ensures the network and root node exist, and adds an edge from the user to the new connection. This made the process much smoother and less error-prone.

On the visualization side, we used the vis-network framework to render the graph. We started with a basic display, but user feedback showed that the graph wasn’t emphasized enough and was hard to navigate, especially as networks grew larger. In response, we added features like a “Center Root” button to help users reorient themselves, and tweaked the layout and sizing to make large networks more readable. One specific piece of feedback was that users wanted the graph to be more visible and accessible from anywhere in the app, so we added an extra bubble on the bottom left that follows the user to every tab and clicking on it pops up the network visualization.

We also made sure that the visualization updates in real time as users add or remove connections, so it always reflects the current state of their network. Balancing automation with user control was tricky. If there's too much automation, users felt lost, but if there's too little, it was overwhelming. In the end, combining automatic network management with an interactive, always-accessible graph visualization made the app much more usable and helped users actually see the value of mapping out their connections.

<br>

## Changes from User Testing

Based on our user testing, we identified several recurring issues and made targeted changes to address them. The table below summarizes the main problems surfaced by both user tests and the corresponding solutions we implemented:

| Issue/Flaw | What We Changed |
|------------|----------------|
| Overly Technical & Confusing Design | Replaced backend/developer jargon (e.g., "node," "edge," etc.) with user-friendly language and familiar metaphors. Clarified all labels, simplified manual connection forms, and hid technical details. |
| Poor User Flow, Navigation & Fragmentation | Streamlined navigation by consolidating and renaming tabs, making main actions (add connection, import, search) central and obvious. Unified all search features into a single page with both keyword and semantic search modes. Added guided flows for common tasks and reduced the number of steps required. |
| Lack of Responsiveness & Feedback | Improved backend performance, added loading/progress indicators for slow actions (e.g., file import, semantic search), and ensured every major action provides visible, timely success/error notifications. |
| Profile Editing & Redundant Elements | Consolidated all profile editing into a single Settings page. Removed or repaired duplicate/broken buttons and eliminated unnecessary pages like Public Profiles. |
| Visualization & Usability Issues | Improved graph usability: added zoom limits, ensured node panels stay in viewport, moved visualization to a more prominent location, and added a persistent bubble that follows the user through every page: clicking on it pops open the network visualization. |
| Overwhelming/Cluttered Interface & Required Fields | Simplified the landing page, added the application name, highlighted the primary action, reduced visual clutter, and clearly marked required fields in forms. |
